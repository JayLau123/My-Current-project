{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the data\n",
    "\n",
    "filepath = f'myC_05_14_2024_1.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(\"Data loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data.keys()))\n",
    "print(list(data[0.04].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data[0.04][10].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def ploy_fit(name, start, end):\n",
    "\n",
    "\n",
    "    # choose some data points to do the least square fitting\n",
    "\n",
    "    power_densities_dic = {i: power_densities[i] for i in range(len(power_densities))}\n",
    "    all_indices = [i for i in range(len(power_densities))]\n",
    "    selected_indices = all_indices[start:end]\n",
    "\n",
    "    selected_pd = {key: power_densities_dic[key] for key in selected_indices}\n",
    "    print(selected_pd)\n",
    "    print()\n",
    "\n",
    "    selected_power_densities = selected_pd\n",
    "    indices = selected_indices\n",
    "\n",
    "    Data_tot=[]\n",
    "\n",
    "    for percentage in percentages:\n",
    "\n",
    "        values = []\n",
    "\n",
    "        for power_density in power_densities:\n",
    "            \n",
    "            values.append(data[percentage][power_density][name])\n",
    "\n",
    "        data1={}\n",
    "\n",
    "        data1[percentage] = values\n",
    "\n",
    "        Data_tot.append(data1)\n",
    "\n",
    "    for d in Data_tot:\n",
    "        for percentage, values in d.items():\n",
    "            \n",
    "            filtered_indices = [i for i in indices if values[i] != 0] # filter out indices whose value is 0 !!!\n",
    "            selected_values = [values[i] for i in filtered_indices]\n",
    "            \n",
    "            if selected_values:\n",
    "                \n",
    "                selected_log_values = [math.log10(value) for value in selected_values] # convert to log scale !!!\n",
    "                selected_log_powers = [math.log10(selected_power_densities[i]) for i in filtered_indices]\n",
    "\n",
    "                # np.polyfit attempts to find a polynomial of degree deg that best fits the data. \n",
    "                # It does this by minimizing the squared error between the polynomialâ€™s predictions and the actual data points in y.\n",
    "                # The function returns the polynomial coefficients in a list, ordered from the highest power to the constant term. For a linear fit (deg=1), \n",
    "\n",
    "                coefficients = np.polyfit(selected_log_powers, selected_log_values, 1) #  deg is set to 1 (linear fit), it returns [slope, intercept]\n",
    "                slope = coefficients[0]\n",
    "\n",
    "                print(f\"Percentage: Er={percentage}, Slope: {slope:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'red40_avg_pop', 'red71_avg_pop', 'red81_avg_pop', 'red91_avg_pop', 'red10_2_avg_pop', \n",
    "    'red11_2_avg_pop', 'red11_3_avg_pop', 'red12_3_avg_pop', 'red13_3_avg_pop', 'red14_3_avg_pop', \n",
    "    'red15_4_avg_pop', 'green50_avg_pop', 'green60_avg_pop', 'green10_1_avg_pop', 'green11_1_avg_pop', \n",
    "    'green12_2_avg_pop', 'green13_2_avg_pop', 'green14_2_avg_pop', 'green15_3_avg_pop', 'red_avg_pop', \n",
    "    'green_avg_pop', 'red_green_total_avg_pop'\n",
    "]\n",
    "\n",
    "\n",
    "percentages = [0.02, 0.04, 0.08, 0.16]\n",
    "power_densities = [1, 5, 10, 20, 40, 80, 100, 200, 400, 800, 1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000, 500000, 1000000, 2000000, 5000000]\n",
    "\n",
    "power_densities_dic={i: power_densities[i] for i in range(len(power_densities))}\n",
    "# power_densities_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = 'red_green_total_avg_pop'\n",
    "start = 6\n",
    "end = 12\n",
    "ploy_fit(name, start, end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upconversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.04, 0.06, 0.08, 0.1, 0.12, 0.15, 0.2, 0.5]\n",
    "power_densities = [10, 20, 40, 80, 1*10**2, 2*10**2, 4*10**2, 8*10**2, 1*10**3, 2*10**3, 4*10**3, 8*10**3, 1*10**4, 2*10**4, 4*10**4, 8*10**4, 1*10**5, 2*10**5, 4*10**5, 8*10**5, 1*10**6, 2*10**6, 4*10**6, 8*10**6, 1*10**7]\n",
    "\n",
    "upconversion_list = [[] for i in range(len(percentages))]\n",
    "\n",
    "for i, percentage in enumerate(percentages):\n",
    "    for power_density in power_densities:\n",
    "        upconversion_list[i].append(data[percentage][power_density]['tm_upconversions'])\n",
    "    \n",
    "print(len(upconversion_list))\n",
    "print(len(upconversion_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "upconversion_counts=[[] for i in range(len(percentages))]\n",
    "\n",
    "for i, p1 in enumerate(percentages):\n",
    "    for j, p2 in enumerate(power_densities):\n",
    "\n",
    "        my_list = upconversion_list[i][j]\n",
    "        \n",
    "        # Initialize defaultdict to count cumulative values of keys\n",
    "        key_counts = defaultdict(int)\n",
    "\n",
    "        # Iterate through each dictionary in the list\n",
    "        for d in my_list:\n",
    "            for key, value in d.items():\n",
    "                key_counts[key] += value\n",
    "\n",
    "        upconversion_count = {}\n",
    "        upconversion_count[(p1,p2)] = key_counts\n",
    "        upconversion_counts[i].append(upconversion_count)\n",
    "\n",
    "print(len(upconversion_counts))\n",
    "print(len(upconversion_counts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "for i in range(len(upconversion_counts[0])):\n",
    "    # Extracting the current entry (only one key per dict based on your structure)\n",
    "    for key, dd in upconversion_counts[0][i].items():\n",
    "        # Convert defaultdict to regular dict\n",
    "        regular_dict = dict(dd)\n",
    "        # Sort keys by the sum of the tuples\n",
    "        sorted_dict = dict(sorted(regular_dict.items(), key=lambda item: sum(item[0])))\n",
    "        total_sum = sum(sorted_dict.values())\n",
    "        # Printing the updated dictionary with sorted keys\n",
    "        print({key: sorted_dict})\n",
    "        print(f'Total={total_sum}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(upconversion_counts[7])):\n",
    "    # Extracting the current entry (only one key per dict based on your structure)\n",
    "    for key, dd in upconversion_counts[7][i].items():\n",
    "        # Convert defaultdict to regular dict\n",
    "        regular_dict = dict(dd)\n",
    "        # Sort keys by the sum of the tuples\n",
    "        sorted_dict = dict(sorted(regular_dict.items(), key=lambda item: sum(item[0])))\n",
    "        total_sum = sum(sorted_dict.values())\n",
    "        # Printing the updated dictionary with sorted keys\n",
    "        print({key: sorted_dict})\n",
    "        print(f'Total={total_sum}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.04, 0.06, 0.08, 0.1, 0.12, 0.15, 0.2, 0.5]\n",
    "power_densities = [10, 20, 40, 80, 1*10**2, 2*10**2, 4*10**2, 8*10**2, 1*10**3, 2*10**3, 4*10**3, 8*10**3, 1*10**4, 2*10**4, 4*10**4, 8*10**4, 1*10**5, 2*10**5, 4*10**5, 8*10**5, 1*10**6, 2*10**6, 4*10**6, 8*10**6, 1*10**7]\n",
    "\n",
    "crossrelaxation_list = [[] for i in range(len(percentages))]\n",
    "\n",
    "for i, percentage in enumerate(percentages):\n",
    "    for power_density in power_densities:\n",
    "        crossrelaxation_list[i].append(data[percentage][power_density]['tm_crossrelaxations'])\n",
    "    \n",
    "print(len(crossrelaxation_list))\n",
    "print(len(crossrelaxation_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "crossrelaxation_counts=[[] for i in range(len(percentages))]\n",
    "\n",
    "for i, p1 in enumerate(percentages):\n",
    "    for j, p2 in enumerate(power_densities):\n",
    "\n",
    "        my_list = crossrelaxation_list[i][j]\n",
    "        \n",
    "        # Initialize defaultdict to count cumulative values of keys\n",
    "        key_counts = defaultdict(int)\n",
    "\n",
    "        # Iterate through each dictionary in the list\n",
    "        for d in my_list:\n",
    "            for key, value in d.items():\n",
    "                key_counts[key] += value\n",
    "\n",
    "        crossrelaxation_count = {}\n",
    "        crossrelaxation_count[(p1,p2)] = key_counts\n",
    "        crossrelaxation_counts[i].append(crossrelaxation_count)\n",
    "\n",
    "print(len(crossrelaxation_counts))\n",
    "print(len(crossrelaxation_counts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "for i in range(len(crossrelaxation_counts[0])):\n",
    "    # Extracting the current entry (only one key per dict based on your structure)\n",
    "    for key, dd in crossrelaxation_counts[0][i].items():\n",
    "        # Convert defaultdict to regular dict\n",
    "        regular_dict = dict(dd)\n",
    "        # Sort keys by the sum of the tuples\n",
    "        sorted_dict = dict(sorted(regular_dict.items(), key=lambda item: sum(item[0])))\n",
    "        total_sum = sum(sorted_dict.values())\n",
    "        # Printing the updated dictionary with sorted keys\n",
    "        print({key: sorted_dict})\n",
    "        print(f'Total={total_sum}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "for i in range(len(crossrelaxation_counts[7])):\n",
    "    # Extracting the current entry (only one key per dict based on your structure)\n",
    "    for key, dd in crossrelaxation_counts[7][i].items():\n",
    "        # Convert defaultdict to regular dict\n",
    "        regular_dict = dict(dd)\n",
    "        # Sort keys by the sum of the tuples\n",
    "        sorted_dict = dict(sorted(regular_dict.items(), key=lambda item: sum(item[0])))\n",
    "        total_sum = sum(sorted_dict.values())\n",
    "        # Printing the updated dictionary with sorted keys\n",
    "        print({key: sorted_dict})\n",
    "        print(f'Total={total_sum}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
